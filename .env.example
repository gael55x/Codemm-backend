
# Backend HTTP port
PORT=4000

# JWT Secret for authentication (change in production!)
JWT_SECRET=your-secret-key-change-in-production

JUDGE_TIMEOUT_MS=15000

# /run timeout (ms) for code-only execution (cap: 30000)
# CODEMM_RUN_TIMEOUT_MS=8000

# Optional SSE tracing (sanitized; no prompts/raw generations/reference artifacts)
# CODEMM_TRACE=1
# CODEMM_TRACE_FULL=1
# CODEMM_TRACE_TEST_SUITES=1

# Optional dev logging (safe summaries only; no prompts/raw generations/reference artifacts)
# CODEMM_LOG_CONVERSATION=1
# CODEMM_HTTP_LOG=1

# Optional: enable Java "workspace mode" generation where supported
# CODEMM_WORKSPACE_GEN=1
# Codex (OpenAI-compatible) LLM settings
CODEX_API_KEY=your-codex-api-key
# Optional overrides
# CODEX_MODEL=gpt-4.1
# CODEX_BASE_URL=https://your-codex-endpoint
